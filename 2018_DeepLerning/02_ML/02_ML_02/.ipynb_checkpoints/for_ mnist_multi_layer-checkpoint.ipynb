{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fcfa823f940>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fcfa8235710>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7fcfa81d2be0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 下面使用第一次开始使用的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算每一次层网络\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    wx_b = tf.matmul(inputs, weights) + biases\n",
    "    return wx_b if activation_function is None else activation_function(wx_b,)\n",
    "\n",
    "xs = tf.placeholder(tf.float32, [None, 28*28])\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "\n",
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return sess.run(accuracy, feed_dict={xs:v_xs, ys:v_ys})\n",
    "\n",
    "def model_mnist(learning_rate, avf=None):\n",
    "    layer1 = add_layer(xs, 784, 50, activation_function = avf)\n",
    "    layer2 = add_layer(layer1, 50, 50, activation_function = avf)\n",
    "    layer3 = add_layer(layer2, 50, 50, activation_function = avf)\n",
    "    layer4 = add_layer(layer3, 50, 50, activation_function = avf)\n",
    "    prediction = add_layer(layer4, 50, 10, activation_function = tf.nn.softmax)\n",
    "\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), \n",
    "                                  reduction_indices=[1]))\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    return (layer1, prediction, train_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 ,  0.0941\n",
      "step: 1000 ,  0.5389\n",
      "step: 2000 ,  0.6202\n",
      "step: 3000 ,  0.6602\n",
      "step: 4000 ,  0.6872\n",
      "step: 5000 ,  0.7042\n",
      "step: 6000 ,  0.7199\n",
      "step: 7000 ,  0.7271\n",
      "step: 8000 ,  0.7371\n",
      "step: 9000 ,  0.7451\n",
      "step: 10000 ,  0.7504\n",
      "step: 11000 ,  0.7507\n",
      "step: 12000 ,  0.7578\n",
      "step: 13000 ,  0.7597\n",
      "step: 14000 ,  0.7633\n",
      "step: 15000 ,  0.7663\n",
      "step: 16000 ,  0.7679\n",
      "step: 17000 ,  0.7692\n",
      "step: 18000 ,  0.7711\n",
      "step: 19000 ,  0.7735\n",
      "step: 20000 ,  0.7761\n",
      "step: 21000 ,  0.7754\n",
      "step: 22000 ,  0.7771\n",
      "step: 23000 ,  0.7779\n",
      "step: 24000 ,  0.779\n",
      "step: 25000 ,  0.7806\n",
      "step: 26000 ,  0.7811\n",
      "step: 27000 ,  0.7842\n",
      "step: 28000 ,  0.7829\n",
      "step: 29000 ,  0.7832\n",
      "step: 30000 ,  0.785\n",
      "step: 31000 ,  0.7851\n",
      "step: 32000 ,  0.786\n",
      "step: 33000 ,  0.7851\n",
      "step: 34000 ,  0.787\n",
      "step: 35000 ,  0.7882\n",
      "step: 36000 ,  0.7863\n",
      "step: 37000 ,  0.7866\n",
      "step: 38000 ,  0.7884\n",
      "step: 39000 ,  0.7901\n",
      "step: 40000 ,  0.7878\n",
      "step: 41000 ,  0.7891\n",
      "step: 42000 ,  0.7881\n",
      "step: 43000 ,  0.7891\n",
      "step: 44000 ,  0.7893\n",
      "step: 45000 ,  0.7888\n",
      "step: 46000 ,  0.7902\n",
      "step: 47000 ,  0.7903\n",
      "step: 48000 ,  0.79\n",
      "step: 49000 ,  0.7905\n",
      "step: 0 ,  0.0986\n",
      "step: 1000 ,  0.5937\n",
      "step: 2000 ,  0.7106\n",
      "step: 3000 ,  0.7665\n",
      "step: 4000 ,  0.7972\n",
      "step: 5000 ,  0.8153\n",
      "step: 6000 ,  0.8338\n",
      "step: 7000 ,  0.8442\n",
      "step: 8000 ,  0.854\n",
      "step: 9000 ,  0.8633\n",
      "step: 10000 ,  0.8698\n",
      "step: 11000 ,  0.8753\n",
      "step: 12000 ,  0.8816\n",
      "step: 13000 ,  0.8837\n",
      "step: 14000 ,  0.8887\n",
      "step: 15000 ,  0.8901\n",
      "step: 16000 ,  0.8938\n",
      "step: 17000 ,  0.8965\n",
      "step: 18000 ,  0.8981\n",
      "step: 19000 ,  0.9003\n",
      "step: 20000 ,  0.9032\n",
      "step: 21000 ,  0.9047\n",
      "step: 22000 ,  0.9064\n",
      "step: 23000 ,  0.9083\n",
      "step: 24000 ,  0.9091\n",
      "step: 25000 ,  0.9114\n",
      "step: 26000 ,  0.9118\n",
      "step: 27000 ,  0.9126\n",
      "step: 28000 ,  0.9131\n",
      "step: 29000 ,  0.9157\n",
      "step: 30000 ,  0.9149\n",
      "step: 31000 ,  0.9162\n",
      "step: 32000 ,  0.9171\n",
      "step: 33000 ,  0.9191\n",
      "step: 34000 ,  0.9192\n",
      "step: 35000 ,  0.9195\n",
      "step: 36000 ,  0.9214\n",
      "step: 37000 ,  0.9216\n",
      "step: 38000 ,  0.9229\n",
      "step: 39000 ,  0.922\n",
      "step: 40000 ,  0.9221\n",
      "step: 41000 ,  0.923\n",
      "step: 42000 ,  0.925\n",
      "step: 43000 ,  0.9241\n",
      "step: 44000 ,  0.925\n",
      "step: 45000 ,  0.9245\n",
      "step: 46000 ,  0.9252\n",
      "step: 47000 ,  0.9257\n",
      "step: 48000 ,  0.9253\n",
      "step: 49000 ,  0.9272\n",
      "step: 0 ,  0.098\n",
      "step: 1000 ,  0.098\n",
      "step: 2000 ,  0.098\n",
      "step: 3000 ,  0.098\n",
      "step: 4000 ,  0.098\n",
      "step: 5000 ,  0.098\n",
      "step: 6000 ,  0.098\n",
      "step: 7000 ,  0.098\n",
      "step: 8000 ,  0.098\n",
      "step: 9000 ,  0.098\n",
      "step: 10000 ,  0.098\n",
      "step: 11000 ,  0.098\n",
      "step: 12000 ,  0.098\n",
      "step: 13000 ,  0.098\n",
      "step: 14000 ,  0.098\n",
      "step: 15000 ,  0.098\n",
      "step: 16000 ,  0.098\n",
      "step: 17000 ,  0.098\n",
      "step: 18000 ,  0.098\n",
      "step: 19000 ,  0.098\n",
      "step: 20000 ,  0.098\n",
      "step: 21000 ,  0.098\n",
      "step: 22000 ,  0.098\n",
      "step: 23000 ,  0.098\n",
      "step: 24000 ,  0.098\n",
      "step: 25000 ,  0.098\n",
      "step: 26000 ,  0.098\n",
      "step: 27000 ,  0.098\n",
      "step: 28000 ,  0.098\n",
      "step: 29000 ,  0.098\n",
      "step: 30000 ,  0.098\n",
      "step: 31000 ,  0.098\n",
      "step: 32000 ,  0.098\n",
      "step: 33000 ,  0.098\n",
      "step: 34000 ,  0.098\n",
      "step: 35000 ,  0.098\n",
      "step: 36000 ,  0.098\n",
      "step: 37000 ,  0.098\n",
      "step: 38000 ,  0.098\n",
      "step: 39000 ,  0.098\n",
      "step: 40000 ,  0.098\n",
      "step: 41000 ,  0.098\n",
      "step: 42000 ,  0.098\n",
      "step: 43000 ,  0.098\n",
      "step: 44000 ,  0.098\n",
      "step: 45000 ,  0.098\n",
      "step: 46000 ,  0.098\n",
      "step: 47000 ,  0.098\n",
      "step: 48000 ,  0.098\n",
      "step: 49000 ,  0.098\n"
     ]
    }
   ],
   "source": [
    "# 解读1 不同激励函数模型\n",
    "activation_functions = [tf.nn.tanh, tf.nn.sigmoid, tf.nn.relu]\n",
    "models = {}\n",
    "for avf in activation_functions:\n",
    "    layer1, prediction, train_step = model_mnist(0.05,avf)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "    #     初始化我们创建的变量\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        steps = []\n",
    "        accuracy_s = []\n",
    "        for i in range(50000):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(200)\n",
    "    #         训练模型 \n",
    "            sess.run(layer1,  feed_dict = {xs: batch_xs, ys: batch_ys})\n",
    "\n",
    "            sess.run(train_step, feed_dict = {xs: batch_xs, ys:batch_ys})\n",
    "            if i % 1000 ==0:\n",
    "                accuracy = compute_accuracy(mnist.test.images, mnist.test.labels)\n",
    "                accuracy_s.append(accuracy)\n",
    "                steps.append(i)\n",
    "                print (\"step:\",i,\", \",accuracy)\n",
    "    models[str(avf.__name__)] = {'steps':steps,'accuracy_s':accuracy_s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'relu': {'accuracy_s': [0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997],\n",
       "  'steps': [0,\n",
       "   1000,\n",
       "   2000,\n",
       "   3000,\n",
       "   4000,\n",
       "   5000,\n",
       "   6000,\n",
       "   7000,\n",
       "   8000,\n",
       "   9000,\n",
       "   10000,\n",
       "   11000,\n",
       "   12000,\n",
       "   13000,\n",
       "   14000,\n",
       "   15000,\n",
       "   16000,\n",
       "   17000,\n",
       "   18000,\n",
       "   19000,\n",
       "   20000,\n",
       "   21000,\n",
       "   22000,\n",
       "   23000,\n",
       "   24000,\n",
       "   25000,\n",
       "   26000,\n",
       "   27000,\n",
       "   28000,\n",
       "   29000,\n",
       "   30000,\n",
       "   31000,\n",
       "   32000,\n",
       "   33000,\n",
       "   34000,\n",
       "   35000,\n",
       "   36000,\n",
       "   37000,\n",
       "   38000,\n",
       "   39000,\n",
       "   40000,\n",
       "   41000,\n",
       "   42000,\n",
       "   43000,\n",
       "   44000,\n",
       "   45000,\n",
       "   46000,\n",
       "   47000,\n",
       "   48000,\n",
       "   49000]},\n",
       " 'sigmoid': {'accuracy_s': [0.0986,\n",
       "   0.59369999,\n",
       "   0.71060002,\n",
       "   0.7665,\n",
       "   0.79720002,\n",
       "   0.81529999,\n",
       "   0.83380002,\n",
       "   0.84420002,\n",
       "   0.85399997,\n",
       "   0.86330003,\n",
       "   0.86979997,\n",
       "   0.87529999,\n",
       "   0.88160002,\n",
       "   0.88370001,\n",
       "   0.88870001,\n",
       "   0.8901,\n",
       "   0.89380002,\n",
       "   0.89649999,\n",
       "   0.89810002,\n",
       "   0.90030003,\n",
       "   0.90319997,\n",
       "   0.90469998,\n",
       "   0.90640002,\n",
       "   0.90829998,\n",
       "   0.9091,\n",
       "   0.91140002,\n",
       "   0.91180003,\n",
       "   0.91259998,\n",
       "   0.9131,\n",
       "   0.91570002,\n",
       "   0.9149,\n",
       "   0.91619998,\n",
       "   0.91710001,\n",
       "   0.91909999,\n",
       "   0.9192,\n",
       "   0.91949999,\n",
       "   0.92140001,\n",
       "   0.92159998,\n",
       "   0.92290002,\n",
       "   0.92199999,\n",
       "   0.92210001,\n",
       "   0.92299998,\n",
       "   0.92500001,\n",
       "   0.92409998,\n",
       "   0.92500001,\n",
       "   0.92449999,\n",
       "   0.92519999,\n",
       "   0.92570001,\n",
       "   0.9253,\n",
       "   0.92720002],\n",
       "  'steps': [0,\n",
       "   1000,\n",
       "   2000,\n",
       "   3000,\n",
       "   4000,\n",
       "   5000,\n",
       "   6000,\n",
       "   7000,\n",
       "   8000,\n",
       "   9000,\n",
       "   10000,\n",
       "   11000,\n",
       "   12000,\n",
       "   13000,\n",
       "   14000,\n",
       "   15000,\n",
       "   16000,\n",
       "   17000,\n",
       "   18000,\n",
       "   19000,\n",
       "   20000,\n",
       "   21000,\n",
       "   22000,\n",
       "   23000,\n",
       "   24000,\n",
       "   25000,\n",
       "   26000,\n",
       "   27000,\n",
       "   28000,\n",
       "   29000,\n",
       "   30000,\n",
       "   31000,\n",
       "   32000,\n",
       "   33000,\n",
       "   34000,\n",
       "   35000,\n",
       "   36000,\n",
       "   37000,\n",
       "   38000,\n",
       "   39000,\n",
       "   40000,\n",
       "   41000,\n",
       "   42000,\n",
       "   43000,\n",
       "   44000,\n",
       "   45000,\n",
       "   46000,\n",
       "   47000,\n",
       "   48000,\n",
       "   49000]},\n",
       " 'tanh': {'accuracy_s': [0.094099998,\n",
       "   0.53890002,\n",
       "   0.62019998,\n",
       "   0.6602,\n",
       "   0.68720001,\n",
       "   0.70420003,\n",
       "   0.71990001,\n",
       "   0.72710001,\n",
       "   0.73710001,\n",
       "   0.74510002,\n",
       "   0.75040001,\n",
       "   0.7507,\n",
       "   0.75779998,\n",
       "   0.7597,\n",
       "   0.7633,\n",
       "   0.76630002,\n",
       "   0.76789999,\n",
       "   0.76920003,\n",
       "   0.77109998,\n",
       "   0.77350003,\n",
       "   0.77609998,\n",
       "   0.77539998,\n",
       "   0.77710003,\n",
       "   0.77789998,\n",
       "   0.77899998,\n",
       "   0.78060001,\n",
       "   0.78109998,\n",
       "   0.78420001,\n",
       "   0.78289998,\n",
       "   0.78320003,\n",
       "   0.78500003,\n",
       "   0.78509998,\n",
       "   0.78600001,\n",
       "   0.78509998,\n",
       "   0.787,\n",
       "   0.78820002,\n",
       "   0.7863,\n",
       "   0.78659999,\n",
       "   0.78839999,\n",
       "   0.79009998,\n",
       "   0.78780001,\n",
       "   0.78909999,\n",
       "   0.7881,\n",
       "   0.78909999,\n",
       "   0.78930002,\n",
       "   0.7888,\n",
       "   0.7902,\n",
       "   0.79030001,\n",
       "   0.79000002,\n",
       "   0.79049999],\n",
       "  'steps': [0,\n",
       "   1000,\n",
       "   2000,\n",
       "   3000,\n",
       "   4000,\n",
       "   5000,\n",
       "   6000,\n",
       "   7000,\n",
       "   8000,\n",
       "   9000,\n",
       "   10000,\n",
       "   11000,\n",
       "   12000,\n",
       "   13000,\n",
       "   14000,\n",
       "   15000,\n",
       "   16000,\n",
       "   17000,\n",
       "   18000,\n",
       "   19000,\n",
       "   20000,\n",
       "   21000,\n",
       "   22000,\n",
       "   23000,\n",
       "   24000,\n",
       "   25000,\n",
       "   26000,\n",
       "   27000,\n",
       "   28000,\n",
       "   29000,\n",
       "   30000,\n",
       "   31000,\n",
       "   32000,\n",
       "   33000,\n",
       "   34000,\n",
       "   35000,\n",
       "   36000,\n",
       "   37000,\n",
       "   38000,\n",
       "   39000,\n",
       "   40000,\n",
       "   41000,\n",
       "   42000,\n",
       "   43000,\n",
       "   44000,\n",
       "   45000,\n",
       "   46000,\n",
       "   47000,\n",
       "   48000,\n",
       "   49000]}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe7a035bc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制不同学习函数 accuracy的曲线\n",
    "for avf in activation_functions:\n",
    "    plt.plot(models[str(avf.__name__)]['steps'],models[str(avf.__name__)]['accuracy_s'],label=str(avf.__name__))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('per 1000 steps)')\n",
    "legend = plt.legend(loc='best',shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 ,  0.098\n",
      "step: 1000 ,  0.098\n",
      "step: 2000 ,  0.098\n",
      "step: 3000 ,  0.098\n",
      "step: 4000 ,  0.098\n",
      "step: 5000 ,  0.098\n",
      "step: 6000 ,  0.098\n",
      "step: 7000 ,  0.098\n",
      "step: 8000 ,  0.098\n",
      "step: 9000 ,  0.098\n",
      "step: 10000 ,  0.098\n",
      "step: 11000 ,  0.098\n",
      "step: 12000 ,  0.098\n",
      "step: 13000 ,  0.098\n",
      "step: 14000 ,  0.098\n",
      "step: 15000 ,  0.098\n",
      "step: 16000 ,  0.098\n",
      "step: 17000 ,  0.098\n",
      "step: 18000 ,  0.098\n",
      "step: 19000 ,  0.098\n",
      "step: 20000 ,  0.098\n",
      "step: 21000 ,  0.098\n",
      "step: 22000 ,  0.098\n",
      "step: 23000 ,  0.098\n",
      "step: 24000 ,  0.098\n",
      "step: 25000 ,  0.098\n",
      "step: 26000 ,  0.098\n",
      "step: 27000 ,  0.098\n",
      "step: 28000 ,  0.098\n",
      "step: 29000 ,  0.098\n",
      "step: 30000 ,  0.098\n",
      "step: 31000 ,  0.098\n",
      "step: 32000 ,  0.098\n",
      "step: 33000 ,  0.098\n",
      "step: 34000 ,  0.098\n",
      "step: 35000 ,  0.098\n",
      "step: 36000 ,  0.098\n",
      "step: 37000 ,  0.098\n",
      "step: 38000 ,  0.098\n",
      "step: 39000 ,  0.098\n",
      "step: 40000 ,  0.098\n",
      "step: 41000 ,  0.098\n",
      "step: 42000 ,  0.098\n",
      "step: 43000 ,  0.098\n",
      "step: 44000 ,  0.098\n",
      "step: 45000 ,  0.098\n",
      "step: 46000 ,  0.098\n",
      "step: 47000 ,  0.098\n",
      "step: 48000 ,  0.098\n",
      "step: 49000 ,  0.098\n",
      "step: 0 ,  0.098\n",
      "step: 1000 ,  0.098\n",
      "step: 2000 ,  0.098\n",
      "step: 3000 ,  0.098\n",
      "step: 4000 ,  0.098\n",
      "step: 5000 ,  0.098\n",
      "step: 6000 ,  0.098\n",
      "step: 7000 ,  0.098\n",
      "step: 8000 ,  0.098\n",
      "step: 9000 ,  0.098\n",
      "step: 10000 ,  0.098\n",
      "step: 11000 ,  0.098\n",
      "step: 12000 ,  0.098\n",
      "step: 13000 ,  0.098\n",
      "step: 14000 ,  0.098\n",
      "step: 15000 ,  0.098\n",
      "step: 16000 ,  0.098\n",
      "step: 17000 ,  0.098\n",
      "step: 18000 ,  0.098\n",
      "step: 19000 ,  0.098\n",
      "step: 20000 ,  0.098\n",
      "step: 21000 ,  0.098\n",
      "step: 22000 ,  0.098\n",
      "step: 23000 ,  0.098\n",
      "step: 24000 ,  0.098\n",
      "step: 25000 ,  0.098\n",
      "step: 26000 ,  0.098\n",
      "step: 27000 ,  0.098\n",
      "step: 28000 ,  0.098\n",
      "step: 29000 ,  0.098\n",
      "step: 30000 ,  0.098\n",
      "step: 31000 ,  0.098\n",
      "step: 32000 ,  0.098\n",
      "step: 33000 ,  0.098\n",
      "step: 34000 ,  0.098\n",
      "step: 35000 ,  0.098\n",
      "step: 36000 ,  0.098\n",
      "step: 37000 ,  0.098\n",
      "step: 38000 ,  0.098\n",
      "step: 39000 ,  0.098\n",
      "step: 40000 ,  0.098\n",
      "step: 41000 ,  0.098\n",
      "step: 42000 ,  0.098\n",
      "step: 43000 ,  0.098\n",
      "step: 44000 ,  0.098\n",
      "step: 45000 ,  0.098\n",
      "step: 46000 ,  0.098\n",
      "step: 47000 ,  0.098\n",
      "step: 48000 ,  0.098\n",
      "step: 49000 ,  0.098\n",
      "step: 0 ,  0.098\n",
      "step: 1000 ,  0.098\n",
      "step: 2000 ,  0.098\n",
      "step: 3000 ,  0.098\n",
      "step: 4000 ,  0.098\n",
      "step: 5000 ,  0.098\n",
      "step: 6000 ,  0.098\n",
      "step: 7000 ,  0.098\n",
      "step: 8000 ,  0.098\n",
      "step: 9000 ,  0.098\n",
      "step: 10000 ,  0.098\n",
      "step: 11000 ,  0.098\n",
      "step: 12000 ,  0.098\n",
      "step: 13000 ,  0.098\n",
      "step: 14000 ,  0.098\n",
      "step: 15000 ,  0.098\n",
      "step: 16000 ,  0.098\n",
      "step: 17000 ,  0.098\n",
      "step: 18000 ,  0.098\n",
      "step: 19000 ,  0.098\n",
      "step: 20000 ,  0.098\n",
      "step: 21000 ,  0.098\n",
      "step: 22000 ,  0.098\n",
      "step: 23000 ,  0.098\n",
      "step: 24000 ,  0.098\n",
      "step: 25000 ,  0.098\n",
      "step: 26000 ,  0.098\n",
      "step: 27000 ,  0.098\n",
      "step: 28000 ,  0.098\n",
      "step: 29000 ,  0.098\n",
      "step: 30000 ,  0.098\n",
      "step: 31000 ,  0.098\n",
      "step: 32000 ,  0.098\n",
      "step: 33000 ,  0.098\n",
      "step: 34000 ,  0.098\n",
      "step: 35000 ,  0.098\n",
      "step: 36000 ,  0.098\n",
      "step: 37000 ,  0.098\n",
      "step: 38000 ,  0.098\n",
      "step: 39000 ,  0.098\n",
      "step: 40000 ,  0.098\n",
      "step: 41000 ,  0.098\n",
      "step: 42000 ,  0.098\n",
      "step: 43000 ,  0.098\n",
      "step: 44000 ,  0.098\n",
      "step: 45000 ,  0.098\n",
      "step: 46000 ,  0.098\n",
      "step: 47000 ,  0.098\n",
      "step: 48000 ,  0.098\n",
      "step: 49000 ,  0.098\n",
      "step: 0 ,  0.098\n",
      "step: 1000 ,  0.098\n",
      "step: 2000 ,  0.098\n",
      "step: 3000 ,  0.098\n",
      "step: 4000 ,  0.098\n",
      "step: 5000 ,  0.098\n",
      "step: 6000 ,  0.098\n",
      "step: 7000 ,  0.098\n",
      "step: 8000 ,  0.098\n",
      "step: 9000 ,  0.098\n",
      "step: 10000 ,  0.098\n",
      "step: 11000 ,  0.098\n",
      "step: 12000 ,  0.098\n",
      "step: 13000 ,  0.098\n",
      "step: 14000 ,  0.098\n",
      "step: 15000 ,  0.098\n",
      "step: 16000 ,  0.098\n",
      "step: 17000 ,  0.098\n",
      "step: 18000 ,  0.098\n",
      "step: 19000 ,  0.098\n",
      "step: 20000 ,  0.098\n",
      "step: 21000 ,  0.098\n",
      "step: 22000 ,  0.098\n",
      "step: 23000 ,  0.098\n",
      "step: 24000 ,  0.098\n",
      "step: 25000 ,  0.098\n",
      "step: 26000 ,  0.098\n",
      "step: 27000 ,  0.098\n",
      "step: 28000 ,  0.098\n",
      "step: 29000 ,  0.098\n",
      "step: 30000 ,  0.098\n",
      "step: 31000 ,  0.098\n",
      "step: 32000 ,  0.098\n",
      "step: 33000 ,  0.098\n",
      "step: 34000 ,  0.098\n",
      "step: 35000 ,  0.098\n",
      "step: 36000 ,  0.098\n",
      "step: 37000 ,  0.098\n",
      "step: 38000 ,  0.098\n",
      "step: 39000 ,  0.098\n",
      "step: 40000 ,  0.098\n",
      "step: 41000 ,  0.098\n",
      "step: 42000 ,  0.098\n",
      "step: 43000 ,  0.098\n",
      "step: 44000 ,  0.098\n",
      "step: 45000 ,  0.098\n",
      "step: 46000 ,  0.098\n",
      "step: 47000 ,  0.098\n",
      "step: 48000 ,  0.098\n",
      "step: 49000 ,  0.098\n"
     ]
    }
   ],
   "source": [
    "# 不同学习率 accuracy\n",
    "learning_rate = [0.2, 0.1, 0.05,0.01]\n",
    "models_lr = {}\n",
    "for lr in learning_rate:\n",
    "    layer1, prediction, train_step = model_mnist(lr,tf.nn.relu)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "    #     初始化我们创建的变量\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        steps = []\n",
    "        accuracy_s = []\n",
    "        for i in range(50000):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(200)\n",
    "    #         训练模型 \n",
    "            sess.run(layer1,  feed_dict = {xs: batch_xs, ys: batch_ys})\n",
    "\n",
    "            sess.run(train_step, feed_dict = {xs: batch_xs, ys:batch_ys})\n",
    "            if i % 1000 ==0:\n",
    "                accuracy = compute_accuracy(mnist.test.images, mnist.test.labels)\n",
    "                accuracy_s.append(accuracy)\n",
    "                steps.append(i)\n",
    "                print (\"step:\",i,\", \",accuracy)\n",
    "    models_lr[str(lr)] = {'steps':steps,'accuracy_s':accuracy_s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.01': {'accuracy_s': [0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997],\n",
       "  'steps': [0,\n",
       "   1000,\n",
       "   2000,\n",
       "   3000,\n",
       "   4000,\n",
       "   5000,\n",
       "   6000,\n",
       "   7000,\n",
       "   8000,\n",
       "   9000,\n",
       "   10000,\n",
       "   11000,\n",
       "   12000,\n",
       "   13000,\n",
       "   14000,\n",
       "   15000,\n",
       "   16000,\n",
       "   17000,\n",
       "   18000,\n",
       "   19000,\n",
       "   20000,\n",
       "   21000,\n",
       "   22000,\n",
       "   23000,\n",
       "   24000,\n",
       "   25000,\n",
       "   26000,\n",
       "   27000,\n",
       "   28000,\n",
       "   29000,\n",
       "   30000,\n",
       "   31000,\n",
       "   32000,\n",
       "   33000,\n",
       "   34000,\n",
       "   35000,\n",
       "   36000,\n",
       "   37000,\n",
       "   38000,\n",
       "   39000,\n",
       "   40000,\n",
       "   41000,\n",
       "   42000,\n",
       "   43000,\n",
       "   44000,\n",
       "   45000,\n",
       "   46000,\n",
       "   47000,\n",
       "   48000,\n",
       "   49000]},\n",
       " '0.05': {'accuracy_s': [0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997],\n",
       "  'steps': [0,\n",
       "   1000,\n",
       "   2000,\n",
       "   3000,\n",
       "   4000,\n",
       "   5000,\n",
       "   6000,\n",
       "   7000,\n",
       "   8000,\n",
       "   9000,\n",
       "   10000,\n",
       "   11000,\n",
       "   12000,\n",
       "   13000,\n",
       "   14000,\n",
       "   15000,\n",
       "   16000,\n",
       "   17000,\n",
       "   18000,\n",
       "   19000,\n",
       "   20000,\n",
       "   21000,\n",
       "   22000,\n",
       "   23000,\n",
       "   24000,\n",
       "   25000,\n",
       "   26000,\n",
       "   27000,\n",
       "   28000,\n",
       "   29000,\n",
       "   30000,\n",
       "   31000,\n",
       "   32000,\n",
       "   33000,\n",
       "   34000,\n",
       "   35000,\n",
       "   36000,\n",
       "   37000,\n",
       "   38000,\n",
       "   39000,\n",
       "   40000,\n",
       "   41000,\n",
       "   42000,\n",
       "   43000,\n",
       "   44000,\n",
       "   45000,\n",
       "   46000,\n",
       "   47000,\n",
       "   48000,\n",
       "   49000]},\n",
       " '0.1': {'accuracy_s': [0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997],\n",
       "  'steps': [0,\n",
       "   1000,\n",
       "   2000,\n",
       "   3000,\n",
       "   4000,\n",
       "   5000,\n",
       "   6000,\n",
       "   7000,\n",
       "   8000,\n",
       "   9000,\n",
       "   10000,\n",
       "   11000,\n",
       "   12000,\n",
       "   13000,\n",
       "   14000,\n",
       "   15000,\n",
       "   16000,\n",
       "   17000,\n",
       "   18000,\n",
       "   19000,\n",
       "   20000,\n",
       "   21000,\n",
       "   22000,\n",
       "   23000,\n",
       "   24000,\n",
       "   25000,\n",
       "   26000,\n",
       "   27000,\n",
       "   28000,\n",
       "   29000,\n",
       "   30000,\n",
       "   31000,\n",
       "   32000,\n",
       "   33000,\n",
       "   34000,\n",
       "   35000,\n",
       "   36000,\n",
       "   37000,\n",
       "   38000,\n",
       "   39000,\n",
       "   40000,\n",
       "   41000,\n",
       "   42000,\n",
       "   43000,\n",
       "   44000,\n",
       "   45000,\n",
       "   46000,\n",
       "   47000,\n",
       "   48000,\n",
       "   49000]},\n",
       " '0.2': {'accuracy_s': [0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997,\n",
       "   0.097999997],\n",
       "  'steps': [0,\n",
       "   1000,\n",
       "   2000,\n",
       "   3000,\n",
       "   4000,\n",
       "   5000,\n",
       "   6000,\n",
       "   7000,\n",
       "   8000,\n",
       "   9000,\n",
       "   10000,\n",
       "   11000,\n",
       "   12000,\n",
       "   13000,\n",
       "   14000,\n",
       "   15000,\n",
       "   16000,\n",
       "   17000,\n",
       "   18000,\n",
       "   19000,\n",
       "   20000,\n",
       "   21000,\n",
       "   22000,\n",
       "   23000,\n",
       "   24000,\n",
       "   25000,\n",
       "   26000,\n",
       "   27000,\n",
       "   28000,\n",
       "   29000,\n",
       "   30000,\n",
       "   31000,\n",
       "   32000,\n",
       "   33000,\n",
       "   34000,\n",
       "   35000,\n",
       "   36000,\n",
       "   37000,\n",
       "   38000,\n",
       "   39000,\n",
       "   40000,\n",
       "   41000,\n",
       "   42000,\n",
       "   43000,\n",
       "   44000,\n",
       "   45000,\n",
       "   46000,\n",
       "   47000,\n",
       "   48000,\n",
       "   49000]}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMysMP8fmenu3jpmFeQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe7a5cc1278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制不同学习率 accuracy的曲线\n",
    "for lr in learning_rate:\n",
    "    plt.plot(models_lr[str(lr)]['steps'],models_lr[str(lr)]['accuracy_s'],label=str(lr))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('per 1000 steps)')\n",
    "legend = plt.legend(loc='best',shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 针对relu学习率 训练出的模型进行检查\n",
    "import math\n",
    "def add_layer_x(inputs, in_size, out_size, activation_function=None):\n",
    "    weights = tf.Variable(tf.truncated_normal([in_size, out_size],stddev = 0.1))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    wx_b = tf.matmul(inputs, weights) + biases\n",
    "    return wx_b if activation_function is None else activation_function(wx_b,)\n",
    "\n",
    "xs = tf.placeholder(tf.float32, [None, 28*28])\n",
    "ys = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "\n",
    "def compute_accuracy_x(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return sess.run(accuracy, feed_dict={xs:v_xs, ys:v_ys})\n",
    "\n",
    "def model_mnist_x(learning_rate, avf=None):\n",
    "    layer1 = add_layer_x(xs, 784, 50, activation_function = avf)\n",
    "    layer2 = add_layer_x(layer1, 50, 50, activation_function = avf)\n",
    "    layer3 = add_layer_x(layer2, 50, 50, activation_function = avf)\n",
    "    layer4 = add_layer_x(layer3, 50, 50, activation_function = avf)\n",
    "    prediction = add_layer_x(layer4, 50, 10, activation_function = tf.nn.softmax)\n",
    "    \n",
    "    loss_name = 'lr%s' % str(learning_rate) \n",
    "    with tf.name_scope('loss'):\n",
    "        cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction), \n",
    "                                      reduction_indices=[1]))\n",
    "        tf.summary.scalar(loss_name, cross_entropy) \n",
    "\n",
    "#     train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "    return (layer1, prediction, train_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f8f7de692b0>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f8f7de69208>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f8f6e991be0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,10]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_1', defined at:\n  File \"/home/gl/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/gl/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-6359eaf238ff>\", line 10, in <module>\n    ys = tf.placeholder(tf.float32, [None, 10])\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,10]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,10]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-84c24d397b20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mtrain_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mvalid_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,10]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Placeholder_1', defined at:\n  File \"/home/gl/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/gl/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-6359eaf238ff>\", line 10, in <module>\n    ys = tf.placeholder(tf.float32, [None, 10])\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_1' with dtype float and shape [?,10]\n\t [[Node: Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# 不同学习率 accuracy\n",
    "# learning_rate = [0.2, 0.1, 0.05,0.01]\n",
    "learning_rate = [0.05]\n",
    "models_lx = {}\n",
    "# tf.reset_default_graph()\n",
    "for lr in learning_rate:\n",
    "    layer1, prediction, train_step = model_mnist_x(lr,tf.nn.relu)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "    #     初始化我们创建的变量\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "#         writer = tf.summary.FileWriter(\"/tmp/loss_x\")  \n",
    "        train_writer = tf.summary.FileWriter('/tmp/mnist' + '/train',sess.graph)\n",
    "        valid_writer = tf.summary.FileWriter('/tmp/mnist' + '/valid')\n",
    "        summaries = tf.summary.merge_all()  \n",
    "    \n",
    "        steps = []\n",
    "        accuracy_s = []\n",
    "        for i in range(50000):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(200)\n",
    "    #         训练模型 \n",
    "            sess.run(layer1,  feed_dict = {xs: batch_xs, ys: batch_ys})\n",
    "\n",
    "            sess.run(train_step, feed_dict = {xs: batch_xs, ys:batch_ys})\n",
    "            if i % 1000 ==0:\n",
    "                accuracy = compute_accuracy_x(mnist.test.images, mnist.test.labels)\n",
    "                accuracy_s.append(accuracy)\n",
    "                steps.append(i)\n",
    "                \n",
    "                train_sum = sess.run(summaries,feed_dict = {xs: batch_xs, ys:batch_ys})  \n",
    "                train_writer.add_summary(train_sum, global_step=i)  \n",
    "                valid_sum = sess.run(summaries,feed_dict = {xs: mnist.validation.images, ys:mnist.validation.labels})  \n",
    "                valid_writer.add_summary(valid_sum, global_step=i)  \n",
    "                \n",
    "                print (\"step:\",i,\", \",accuracy)\n",
    "    models_lx[str(lr)] = {'steps':steps,'accuracy_s':accuracy_s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5e11cc978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制不同学习率 accuracy的曲线\n",
    "learning_rate = [0.05]\n",
    "for lr in learning_rate:\n",
    "    plt.plot(models_lx[str(lr)]['steps'],models_lx[str(lr)]['accuracy_s'],label=str(lr))\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('per 1000 steps)')\n",
    "legend = plt.legend(loc='best',shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 命令行输入: tensorboard  --logdir=/tmp/mnist 查看结果\n",
    "# 浏览器输入:127.0.0.1:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 下面全部层应用了scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算每一次层网络\n",
    "# graph = tf.Graph()\n",
    "def add_layer_1(inputs, in_size, out_size, n_layer,activation_function=None):\n",
    "    layer_name = 'layer%s' % n_layer  \n",
    "    with tf.name_scope(layer_name):  \n",
    "        with tf.name_scope('weights'):  \n",
    "            weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "            tf.summary.histogram(layer_name + '/weights', weights)  \n",
    "        with tf.name_scope('biases'):  \n",
    "            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "            tf.summary.histogram(layer_name + '/biases', biases)  \n",
    "        with tf.name_scope('wx_b'):  \n",
    "            wx_b = tf.matmul(inputs, weights) + biases\n",
    "            \n",
    "        outputs = wx_b if activation_function is None else activation_function(wx_b,)  \n",
    "        tf.summary.histogram(layer_name + '/outputs', outputs)  \n",
    "        return outputs\n",
    "    \n",
    "with tf.name_scope('inputs'):  \n",
    "    xs = tf.placeholder(tf.float32, [None, 28*28],name='xs')\n",
    "    ys = tf.placeholder(tf.float32, [None, 10],name='ys')\n",
    "\n",
    "\n",
    "def compute_accuracy_1(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return sess.run(accuracy, feed_dict={xs:v_xs, ys:v_ys})\n",
    "\n",
    "# def model_mnist_1(learning_rate, avf=None):\n",
    "#     layer1 = add_layer_1(xs, 784, 50, n_layer=1,activation_function = avf)\n",
    "#     layer2 = add_layer_1(layer1, 50, 50, n_layer=2, activation_function = avf)\n",
    "#     layer3 = add_layer_1(layer2, 50, 50, n_layer=3, activation_function = avf)\n",
    "#     layer4 = add_layer_1(layer3, 50, 50, n_layer=4, activation_function = avf)\n",
    "#     prediction = add_layer_1(layer4, 50, 10, n_layer=5, activation_function = tf.nn.softmax)\n",
    "\n",
    "#     with tf.name_scope('loss'):  \n",
    "\n",
    "#         cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = ys,logits = prediction))\n",
    "#         tf.summary.scalar('loss', cross_entropy)  \n",
    "\n",
    "#     with tf.name_scope('train'):       \n",
    "#         train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "#     return (layer1, prediction, train_step)\n",
    "\n",
    "\n",
    "layer1 = add_layer_1(xs, 784, 50, n_layer=1,activation_function = tf.nn.relu)\n",
    "layer2 = add_layer_1(layer1, 50, 50, n_layer=2, activation_function = tf.nn.relu)\n",
    "layer3 = add_layer_1(layer2, 50, 50, n_layer=3, activation_function = tf.nn.relu)\n",
    "layer4 = add_layer_1(layer3, 50, 50, n_layer=4, activation_function = tf.nn.relu)\n",
    "prediction = add_layer_1(layer4, 50, 10, n_layer=5, activation_function = tf.nn.softmax)\n",
    "\n",
    "with tf.name_scope('loss'):  \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = ys,logits = prediction))\n",
    "    tf.summary.scalar('loss', cross_entropy)  \n",
    "\n",
    "with tf.name_scope('train'):       \n",
    "    train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'inputs/ys' with dtype float and shape [?,10]\n\t [[Node: inputs/ys = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'inputs/ys', defined at:\n  File \"/home/gl/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/gl/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-14fec53d464c>\", line 21, in <module>\n    ys = tf.placeholder(tf.float32, [None, 10],name='ys')\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'inputs/ys' with dtype float and shape [?,10]\n\t [[Node: inputs/ys = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'inputs/ys' with dtype float and shape [?,10]\n\t [[Node: inputs/ys = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1651b4a6f6e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'inputs/ys' with dtype float and shape [?,10]\n\t [[Node: inputs/ys = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'inputs/ys', defined at:\n  File \"/home/gl/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/gl/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-14fec53d464c>\", line 21, in <module>\n    ys = tf.placeholder(tf.float32, [None, 10],name='ys')\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/gl/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'inputs/ys' with dtype float and shape [?,10]\n\t [[Node: inputs/ys = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# 不同学习率 accuracy\n",
    "# learning_rate = [0.2, 0.1, 0.05,0.01]\n",
    "learning_rate = [0.05]\n",
    "models_1 = {}\n",
    "# tf.reset_default_graph()\n",
    "# with tf.Graph().as_default():sess = tf.InteractiveSession()\n",
    "#     sess = tf.Session()\n",
    "#     with sess.as_default():\n",
    "with tf.Session() as sess:\n",
    "        for lr in learning_rate:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            writer = tf.summary.FileWriter(\"/tmp/logs_min\", sess.graph) \n",
    "            merged = tf.summary.merge_all()  \n",
    "\n",
    "            steps = []\n",
    "            accuracy_s = []\n",
    "\n",
    "            for i in range(10000):\n",
    "                batch_xs, batch_ys = mnist.train.next_batch(200)\n",
    "        #         训练模型 \n",
    "#                 sess.run(layer1,  feed_dict = {xs: batch_xs, ys: batch_ys})\n",
    "                sess.run([layer1,train_step], feed_dict = {xs: batch_xs, ys:batch_ys})\n",
    "                if i % 100 ==0:\n",
    "                    accuracy = compute_accuracy_1(mnist.test.images, mnist.test.labels)\n",
    "                    accuracy_s.append(accuracy)\n",
    "                    steps.append(i)\n",
    "\n",
    "                    result = sess.run(merged,feed_dict = {xs: batch_xs, ys:batch_ys}) \n",
    "                    writer.add_summary(result, global_step=i)  \n",
    "\n",
    "\n",
    "                    print (\"step:\",i,\", \",accuracy)\n",
    "        models_1[str(lr)] = {'steps':steps,'accuracy_s':accuracy_s}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
